from flask import Flask, request, jsonify
import os
import torch
import pandas as pd
import nibabel as nib
import numpy as np
import tempfile
import torchvision.transforms as transforms
import joblib
import json
import matplotlib.pyplot as plt
from datetime import datetime
import requests
import sqlite3
import io
from multimodal_model import MultiModalDiagnosticNet, ViTImageEncoder, EHRFeatureEncoder

# ====================== PATH CONFIGURATION ======================
BASE_DIR = r"C:\Users\Dell\Downloads\PsyProtection-main\multimodal-drug-detector"
MODEL_PATH = os.path.join(BASE_DIR, "multi_modal_diagnostic_model.pkl")
SCALER_PATH = os.path.join(BASE_DIR, "scaler.pkl")
ENCODER_PATH = os.path.join(BASE_DIR, "encoder.pkl")
STATIC_PATH = os.path.join(BASE_DIR, "static")
DATABASE_PATH = os.path.join(BASE_DIR, "predictions.db")

# ====================== APPLICATION SETUP ======================
app = Flask(__name__, static_folder=STATIC_PATH)
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB max upload

# Load model and transformers
model = joblib.load(MODEL_PATH)
scaler = joblib.load(SCALER_PATH)
encoder = joblib.load(ENCODER_PATH)

# Image transform
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((224, 224)),
])

FRIENDLY_TO_MODEL_KEYS = {
    "age": "age",
    "years of education": "educ_yr",
    "occupation level": "occup",
    "annual income": "income",
    "handedness": "laterality",
    "AMAI category": "amai",
    "AMAI score": "amai_score",
    "years since first drug use": "years.begin",
    "age of drug onset": "drug.age.onset",
    "days since last drug use": "days.last.use",
    "weekly dose": "week.dose",
    "tobacco consumed since last year": "tobc.lastyear",
    "tobacco per day": "tobc.day",
    "years of tobacco use": "tobc.totyears",
    "current illness": "illness",
    "current medication": "medication"
}

# ====================== DATABASE FUNCTIONS ======================
def init_db():
    with sqlite3.connect(DATABASE_PATH) as conn:
        c = conn.cursor()
        c.execute('''CREATE TABLE IF NOT EXISTS predictions
                     (id INTEGER PRIMARY KEY AUTOINCREMENT,
                      patient_id TEXT,
                      prediction_prob REAL,
                      prediction_class INTEGER,
                      verdict TEXT,
                      ehr_data TEXT,
                      explanation_url TEXT,
                      query_answer TEXT,
                      timestamp DATETIME,
                      heatmap_path TEXT)''')  # Removed validation_status column
        c.execute('CREATE INDEX IF NOT EXISTS idx_patient_id ON predictions(patient_id)')
        conn.commit()

def store_prediction(patient_id, prediction_prob, prediction_class, verdict, 
                    ehr_data, explanation_url, query_answer, heatmap_path):
    with sqlite3.connect(DATABASE_PATH) as conn:
        c = conn.cursor()
        c.execute('''INSERT INTO predictions 
                     (patient_id, prediction_prob, prediction_class, verdict,
                      ehr_data, explanation_url, query_answer, timestamp, 
                      heatmap_path)
                     VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                  (patient_id, prediction_prob, prediction_class, verdict,
                   json.dumps(ehr_data), explanation_url, query_answer, 
                   datetime.now(), heatmap_path))
        conn.commit()

# ====================== CORE PROCESSING FUNCTIONS ======================
def mri_occlusion_explain_internal(mri_data):
    """Internal version of occlusion explanation without Flask request"""
    try:
        middle_slice = mri_data[:, :, mri_data.shape[2] // 2]
        middle_slice = (middle_slice - np.min(middle_slice)) / (np.max(middle_slice) - np.min(middle_slice))
        image_tensor = transform(middle_slice).unsqueeze(0).float()

        vit = ViTImageEncoder()
        vit.eval()
        classifier = model.classifier
        dummy_ehr = torch.zeros((1, 50))

        with torch.no_grad():
            base_feat = vit(image_tensor)
            base_output = classifier(torch.cat([base_feat, dummy_ehr], dim=1))
            base_pred = base_output.item()
            pred_class = int(base_output >= 0.5)
            confidence = float(base_pred if pred_class == 1 else 1 - base_pred)

        patch_size = 20
        stride = 10
        center_crop = 112
        crop_size = 100
        start = center_crop - crop_size // 2
        end = center_crop + crop_size // 2
        heatmap = np.zeros((224, 224))

        for i in range(start, end - patch_size, stride):
            for j in range(start, end - patch_size, stride):
                perturbed = image_tensor.clone()
                perturbed[:, :, i:i+patch_size, j:j+patch_size] = 0
                with torch.no_grad():
                    feat = vit(perturbed)
                    pred = classifier(torch.cat([feat, dummy_ehr], dim=1)).item()
                delta = base_pred - pred
                heatmap[i:i+patch_size, j:j+patch_size] += delta

        heatmap = np.maximum(heatmap, 0)
        heatmap = heatmap / np.max(heatmap + 1e-8)

        os.makedirs(STATIC_PATH, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        heatmap_filename = f"heatmap_{timestamp}.png"
        heatmap_path = os.path.join(STATIC_PATH, heatmap_filename)

        fig, ax = plt.subplots()
        ax.imshow(middle_slice, cmap='gray')
        ax.imshow(heatmap, cmap='jet', alpha=0.5)
        ax.axis('off')
        plt.savefig(heatmap_path, format='png', bbox_inches='tight', pad_inches=0)
        plt.close(fig)

        generate_summary(pred_class, confidence, heatmap_path)

        return {
            "explanation": "Occlusion-based explanation complete.",
            "base_prediction": base_pred,
            "heatmap_url": f"/static/{heatmap_filename}",
            "summary_file": heatmap_filename.replace(".png", "_summary.txt")
        }

    except Exception as e:
        return {"error": str(e)}

def generate_summary(prediction, confidence, heatmap_path):
    summary_text = f"""Prediction Summary

ðŸ§  Prediction: {'Drug Abuser' if prediction == 1 else 'Non-Abuser'}
ðŸ“Š Confidence: {confidence * 100:.2f}%

Explanation:
This heatmap highlights regions of the brain that influenced the model's decision. 
Red = high impact, Blue = low impact on prediction.

These regions are consistent with neural patterns observed in drug abuse-related cases during training.
"""
    summary_path = heatmap_path.replace(".png", "_summary.txt")
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write(summary_text)

# ====================== ROUTES ======================
@app.route('/drug_abuse_detector', methods=['POST'])
def drug_abuse_detector():
    try:
        # Check for required files and data
        if 'file' not in request.files:
            return jsonify({"error": "No MRI file uploaded"}), 400
            
        file = request.files['file']
        file_stream = io.BytesIO()
        file.save(file_stream)
        file_stream.seek(0)
        
        # Process EHR data
        patient_id = request.form.get('patient_id', 'unknown')
        ehr_raw = request.form.get('EHR_features')
        if not ehr_raw:
            return jsonify({"error": "No EHR data provided"}), 400
            
        try:
            ehr_dict = json.loads(ehr_raw)
        except json.JSONDecodeError:
            return jsonify({"error": "Invalid EHR JSON format"}), 400

        # Prepare MRI data
        file_stream.seek(0)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".nii.gz") as temp_file:
            file_stream.save(temp_file.name)
            try:
                mri_scan = nib.load(temp_file.name)
                mri_data = mri_scan.get_fdata()
            except Exception as e:
                return jsonify({"error": f"Failed to load MRI file: {str(e)}"}), 400
        
        mri_data = mri_data.reshape(-1, mri_data.shape[1])
        mri_data = (mri_data - np.min(mri_data)) / (np.max(mri_data) - np.min(mri_data))
        mri_data = transform(mri_data).unsqueeze(0).float()
        
        # Prepare EHR features
        ehr_model_ready = {
            FRIENDLY_TO_MODEL_KEYS.get(k, k): v for k, v in ehr_dict.items()
        }

        ehr_df = pd.DataFrame([ehr_model_ready])
        numeric_cols = ehr_df.select_dtypes(include=['int64', 'float64']).columns
        categorical_cols = ehr_df.select_dtypes(include=['object', 'category']).columns
        ehr_df[numeric_cols] = scaler.transform(ehr_df[numeric_cols])
        ehr_df[categorical_cols] = encoder.transform(ehr_df[categorical_cols])
        ehr_tensor = torch.from_numpy(ehr_df.values).float()
        
        # Make prediction
        with torch.no_grad():
            predictions = model(mri_data, ehr_tensor)
            predicted_prob = predictions.item()
            predicted_class = (predictions >= 0.5).float()

        verdict = "Drug abuser" if predicted_class == 1 else "Not a drug abuser"
        ehr_dict["Verdict"] = verdict

        # Generate explanation if positive
        heatmap_path = None
        if predicted_class == 1:
            explanation = mri_occlusion_explain_internal(mri_data)
            if "error" in explanation:
                return jsonify({"error": f"Explanation failed: {explanation['error']}"}), 500
            heatmap_path = explanation['heatmap_url'].split('/static/')[-1]
        else:
            explanation = {"heatmap_url": None}

        # Get RAG answer if needed
        query_answer = None
        if predicted_class == 1:
            medication = ehr_dict.get("medication", "")
            illness = ehr_dict.get("illness", "")
            if medication and illness:
                rag_query = f"newest treatments for {medication} addiction for {illness} patients"
                try:
                    response = requests.post("http://127.0.0.1:8000/ask_question", 
                                         json={"query": rag_query})
                    query_answer = response.json().get("answer", "No answer found.")
                except Exception as e:
                    query_answer = f"Error retrieving RAG answer: {str(e)}"

        # Store everything in database
        store_prediction(
            patient_id=patient_id,
            prediction_prob=float(predicted_prob),
            prediction_class=int(predicted_class),
            verdict=verdict,
            ehr_data=ehr_dict,
            explanation_url=explanation['heatmap_url'],
            query_answer=query_answer,
            heatmap_path=heatmap_path
        )

        return jsonify({
            "prediction": {
                "probability": float(predicted_prob),
                "class": int(predicted_class),
                "description": verdict
            },
            "explanation": explanation['heatmap_url'],
            "query_answer": query_answer
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 400

@app.route('/mri_occlusion_explain', methods=['POST'])
def mri_occlusion_explain():
    """Public endpoint for occlusion explanation"""
    try:
        file = request.files['file']
        with tempfile.NamedTemporaryFile(delete=False, suffix=".nii.gz") as temp_file:
            file.save(temp_file.name)
            mri_scan = nib.load(temp_file.name)
            mri_data = mri_scan.get_fdata()
        
        result = mri_occlusion_explain_internal(mri_data)
        if "error" in result:
            return jsonify(result), 400
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 400

@app.route('/get_predictions', methods=['GET'])
def get_predictions():
    """Retrieve stored predictions"""
    try:
        patient_id = request.args.get('patient_id')
        limit = request.args.get('limit', 100)
        
        with sqlite3.connect(DATABASE_PATH) as conn:
            conn.row_factory = sqlite3.Row
            c = conn.cursor()
            
            if patient_id:
                c.execute('SELECT * FROM predictions WHERE patient_id = ? ORDER BY timestamp DESC LIMIT ?', 
                         (patient_id, limit))
            else:
                c.execute('SELECT * FROM predictions ORDER BY timestamp DESC LIMIT ?', (limit,))
                
            predictions = [dict(row) for row in c.fetchall()]
            
        return jsonify(predictions)
    except Exception as e:
        return jsonify({"error": str(e)}), 400

if __name__ == '__main__':
    os.makedirs(STATIC_PATH, exist_ok=True)
    init_db()
    app.run(host='0.0.0.0', port=5000)
